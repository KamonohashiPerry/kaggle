{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSB2019_V77_TR_DT_AUG0.5_3TTA_Copy_ReverseEngineering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOLdSPAlaSsoDV4kNBiCx0R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KamonohashiPerry/kaggle/blob/master/DSB2019_V77_TR_DT_AUG0_5_3TTA_Copy_ReverseEngineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDlQjo_pRAAH",
        "colab_type": "text"
      },
      "source": [
        "## PyTorchのインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyhIzO_0Qquj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install http://download.pytorch.org/whl/cu80/torch-0.4.0-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKh4BJaRQ2Kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nln6uUt4VUuK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "772d60b1-de4f-468b-ad62-b5b1972872a9"
      },
      "source": [
        "# 毎回インストールする\n",
        "pip install pytorch-transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.0.38)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.1.85)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.17.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.4.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.11.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.11.28)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.3.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-transformers) (2.6.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc2O_GbDGvvT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "fd040838-0ecf-4cde-beeb-cf050f5f9f52"
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 145113 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.17-0ubuntu2~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.17-0ubuntu2~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.17-0ubuntu2~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPlm0cVEG1ZO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "d47ed2c7-837a-4007-b54b-c6ff4d03e5d7"
      },
      "source": [
        "# drive mean root directory of  google drive\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "!ls drive/\"Colab Notebooks\"/Kaggle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fuse: mountpoint is not empty\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\n",
            " b-32_a-TRANSFORMER_e-100_h-500_d-0.2_l-2_hd-10_s-7_len-100_aug-0.5_da-bowl_v62.pt_k-0.pt\n",
            " b-32_a-TRANSFORMER_e-100_h-500_d-0.2_l-2_hd-10_s-7_len-100_aug-0.5_da-bowl_v62.pt_k-1.pt\n",
            " b-32_a-TRANSFORMER_e-100_h-500_d-0.2_l-2_hd-10_s-7_len-100_aug-0.5_da-bowl_v62.pt_k-2.pt\n",
            " b-32_a-TRANSFORMER_e-100_h-500_d-0.2_l-2_hd-10_s-7_len-100_aug-0.5_da-bowl_v62.pt_k-3.pt\n",
            " b-32_a-TRANSFORMER_e-100_h-500_d-0.2_l-2_hd-10_s-7_len-100_aug-0.5_da-bowl_v62.pt_k-4.pt\n",
            " bowl_info_v70.pt\n",
            " DataScienceBowl_2019_v1.ipynb\n",
            " DataScienceBowl_2019_v2.ipynb\n",
            " DataScienceBowl_2019_v3.ipynb\n",
            "'DSB2019 - BS 26 (lgb_auc+xgb) Copy.ipynb'\n",
            " DSB2019_V77_TR_DT_AUG0.5_3TTA_Copy.ipynb\n",
            " kaggle_check_data.desktop\n",
            " kaggle.json\n",
            " PSI_Tutorial.ipynb\n",
            " test.csv\n",
            " Titanic_v1.ipynb\n",
            " Titanic_v2.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rXmJqHWazqU",
        "colab_type": "text"
      },
      "source": [
        "## Reference\n",
        "https://www.kaggle.com/limerobot/dsb2019-v77-tr-dt-aug0-5-3tta/comments\n",
        "\n",
        "\n",
        "## メモ\n",
        "+ テストデータだけで訓練データのパートがない？\n",
        "+ このままだと解読が大変なので、関数をバラして1行ずつ挙動を見て言ったほうがいい。その過程でpytorchの理解も深まるはず。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQlKXhPPxSnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import gc\n",
        "import time\n",
        "import random\n",
        "\n",
        "from scipy import optimize\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from pytorch_transformers.modeling_bert import BertConfig, BertEncoder\n",
        "\n",
        "\n",
        "# 関数やメソッドの引数の一部をある値に固定して新しいオブジェクトを作れる\n",
        "from functools import partial\n",
        "# 高速化のため\n",
        "from numba import jit\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "# パラメータの設定\n",
        "class CFG:\n",
        "    learning_rate=1.0e-4\n",
        "    batch_size=64\n",
        "    num_workers=4\n",
        "    print_freq=100\n",
        "    test_freq=1\n",
        "    start_epoch=0\n",
        "    num_train_epochs=1\n",
        "    warmup_steps=30\n",
        "    max_grad_norm=1000\n",
        "    gradient_accumulation_steps=1\n",
        "    weight_decay=0.01    \n",
        "    dropout=0.2\n",
        "    emb_size=100 # 分散表現の次元\n",
        "    hidden_size=500 # 隠れ層の数\n",
        "    nlayers=2\n",
        "    nheads=8    \n",
        "    device='cpu'\n",
        "    seed=7\n",
        "    ntta = [0, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6] # TEST KAPPA_SCORE:0.5990772768904306\n",
        "    wtta = [0.8]\n",
        "CFG.wtta += [ (1-CFG.wtta[0])/(len(CFG.ntta)-1) for _ in range(len(CFG.ntta)-1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBUzukt4lyLd",
        "colab_type": "text"
      },
      "source": [
        "## main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWfg74RkljAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 乱数の固定\n",
        "os.environ['PYTHONHASHSEED'] = str(CFG.seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap3T5FsxqrFo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6620b6c-51f9-4cfb-fea3-28a9ba119bc5"
      },
      "source": [
        "os.environ['PYTHONHASHSEED']"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'7'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udncc8bJqz7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.seed(CFG.seed)\n",
        "np.random.seed(CFG.seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5aiYpljq7g9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You can use torch.manual_seed() to seed the RNG for all devices (both CPU and CUDA)\n",
        "torch.manual_seed(CFG.seed) \n",
        "torch.cuda.manual_seed(CFG.seed)\n",
        "# When running on the CuDNN backend, further option must be set:\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJmAonAJr4K_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv('/content/drive/Colab Notebooks/Kaggle/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM42dRNouoqY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "312a733e-d0fb-45ef-908c-4d7a49bf28d6"
      },
      "source": [
        "test_df.tail(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>event_id</th>\n",
              "      <th>game_session</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>event_data</th>\n",
              "      <th>installation_id</th>\n",
              "      <th>event_count</th>\n",
              "      <th>event_code</th>\n",
              "      <th>game_time</th>\n",
              "      <th>title</th>\n",
              "      <th>type</th>\n",
              "      <th>world</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1156409</th>\n",
              "      <td>c74f40cd</td>\n",
              "      <td>46ff9d3ad2be09f2</td>\n",
              "      <td>2019-09-28T21:20:40.918Z</td>\n",
              "      <td>{\"description\":\"Alright! This one is the littl...</td>\n",
              "      <td>ffe774cc</td>\n",
              "      <td>39</td>\n",
              "      <td>3121</td>\n",
              "      <td>32030</td>\n",
              "      <td>Mushroom Sorter (Assessment)</td>\n",
              "      <td>Assessment</td>\n",
              "      <td>TREETOPCITY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156410</th>\n",
              "      <td>6c930e6e</td>\n",
              "      <td>46ff9d3ad2be09f2</td>\n",
              "      <td>2019-09-28T21:20:41.493Z</td>\n",
              "      <td>{\"duration\":20008,\"misses\":0,\"event_count\":40,...</td>\n",
              "      <td>ffe774cc</td>\n",
              "      <td>40</td>\n",
              "      <td>2030</td>\n",
              "      <td>32584</td>\n",
              "      <td>Mushroom Sorter (Assessment)</td>\n",
              "      <td>Assessment</td>\n",
              "      <td>TREETOPCITY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156411</th>\n",
              "      <td>a5be6304</td>\n",
              "      <td>46ff9d3ad2be09f2</td>\n",
              "      <td>2019-09-28T21:20:45.499Z</td>\n",
              "      <td>{\"session_duration\":36607,\"exit_type\":\"game_co...</td>\n",
              "      <td>ffe774cc</td>\n",
              "      <td>41</td>\n",
              "      <td>2010</td>\n",
              "      <td>36607</td>\n",
              "      <td>Mushroom Sorter (Assessment)</td>\n",
              "      <td>Assessment</td>\n",
              "      <td>TREETOPCITY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156412</th>\n",
              "      <td>27253bdc</td>\n",
              "      <td>96d7dc31e822cedc</td>\n",
              "      <td>2019-09-28T21:21:05.670Z</td>\n",
              "      <td>{\"event_code\": 2000, \"event_count\": 1}</td>\n",
              "      <td>ffe774cc</td>\n",
              "      <td>1</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>Tree Top City - Level 3</td>\n",
              "      <td>Clip</td>\n",
              "      <td>TREETOPCITY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156413</th>\n",
              "      <td>f56e0afc</td>\n",
              "      <td>6897df1e7b5ccdf7</td>\n",
              "      <td>2019-09-28T21:21:56.105Z</td>\n",
              "      <td>{\"version\":\"1.0\",\"event_count\":1,\"game_time\":0...</td>\n",
              "      <td>ffe774cc</td>\n",
              "      <td>1</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>Bird Measurer (Assessment)</td>\n",
              "      <td>Assessment</td>\n",
              "      <td>TREETOPCITY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         event_id      game_session  ...        type        world\n",
              "1156409  c74f40cd  46ff9d3ad2be09f2  ...  Assessment  TREETOPCITY\n",
              "1156410  6c930e6e  46ff9d3ad2be09f2  ...  Assessment  TREETOPCITY\n",
              "1156411  a5be6304  46ff9d3ad2be09f2  ...  Assessment  TREETOPCITY\n",
              "1156412  27253bdc  96d7dc31e822cedc  ...        Clip  TREETOPCITY\n",
              "1156413  f56e0afc  6897df1e7b5ccdf7  ...  Assessment  TREETOPCITY\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aer8kSnVtI32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_columnsは訓練用データのカラム\n",
        "# mappers_dictはタイトルたち\n",
        "# cate_offsetは53\n",
        "# cate_colsは['title', 'type', 'world']\n",
        "# cont_colsは['event_count', 'game_time', 'max_game_time']\n",
        "# extra_cont_clsはイベントなどの変数名\n",
        "\n",
        "[train_columns, mappers_dict, cate_offset, \n",
        "  cate_cols, cont_cols, extra_cont_cls] = torch.load('/content/drive/Colab Notebooks/Kaggle/bowl_info_v70.pt') # modelの情報"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QGQfoQi8RUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(df, train_columns, mappers_dict, cate_offset, cate_cols, cont_cols, extra_cont_cls):\n",
        "    print('preprocessing ... ')\n",
        "    replace_4110_4100(df)\n",
        "    \n",
        "    print('generating label ...')\n",
        "    label_df = gen_label(df)\n",
        "    \n",
        "    print('extract_data_from_event_code ...')\n",
        "    extract_data_from_event_code(df)\n",
        "    df['num_incorrect'] = np.where(df['correct']==0, 1, np.nan)\n",
        "    df['num_correct'] = np.where(df['correct']==1, 1, np.nan)\n",
        "    \n",
        "    df['game_time'] = df['game_time'] // 1000\n",
        "    \n",
        "    df = get_agged_session(df)\n",
        "    df = df.drop(['correct', 'round', 'num_correct', 'num_incorrect'], axis=1)\n",
        "    \n",
        "    df = df.merge(label_df, on=['game_session', 'installation_id'], how='left')\n",
        "    \n",
        "    samples, groups = get_train_sample_indices(df)\n",
        "    \n",
        "    df = df.append(pd.DataFrame(columns=train_columns))[train_columns]\n",
        "    df = df.fillna(0)\n",
        "    \n",
        "    for col in cate_cols:\n",
        "        df[col] = df[col].map(mappers_dict[col]).fillna(0).astype(int)\n",
        "    \n",
        "    print('preprocessing ... done')        \n",
        "    return df, samples, groups\n",
        "\n",
        "def replace_4110_4100(df):\n",
        "    rep_code4110_bool = (df['title']=='Bird Measurer (Assessment)')&(df['event_code']==4110)\n",
        "    rep_code4100_bool = (df['title']=='Bird Measurer (Assessment)')&(df['event_code']==4100)\n",
        "    df['event_code'][rep_code4110_bool] = 4100\n",
        "    df['event_code'][rep_code4100_bool] = 5110\n",
        "\n",
        "# testデータからラベルを生成することができるということ？\n",
        "# event_dataにcorrectに関するデータがあり、それを集計すれば正解と不正解がわかる。\n",
        "def gen_label(df):\n",
        "    num_corrects = []\n",
        "    for inst_id, one_df in df.groupby('installation_id'):\n",
        "        one_df = one_df[(one_df['type']=='Assessment')&(one_df['event_code']==4100)]\n",
        "        for game_session, title_df in one_df.groupby('game_session'):            \n",
        "            num_correct = title_df['event_data'].str.contains('\"correct\":true').sum()\n",
        "            num_incorrect = title_df['event_data'].str.contains('\"correct\":false').sum()            \n",
        "            num_corrects.append([inst_id, game_session, num_correct, num_incorrect])\n",
        "    label_df = pd.DataFrame(num_corrects, columns=['installation_id', 'game_session', 'num_correct', 'num_incorrect'])\n",
        "    label_df['accuracy'] = label_df['num_correct'] / (label_df['num_correct']+label_df['num_incorrect'])\n",
        "    label_df['accuracy_group'] = 3\n",
        "    label_df['accuracy_group'][label_df['accuracy']==0.5] = 2    \n",
        "    label_df['accuracy_group'][label_df['accuracy']<0.5] = 1\n",
        "    label_df['accuracy_group'][label_df['accuracy']==0] = 0    \n",
        "    return label_df\n",
        "\n",
        "\n",
        "def extract_data_from_event_code(df, columns=['correct', 'round']):\n",
        "    for col in columns:\n",
        "        col_bool = df['event_data'].str.contains(col)\n",
        "        df[col] = np.nan\n",
        "        df[col][col_bool] = df['event_data'][col_bool].apply(lambda x: json.loads(x).get(col)).astype(float)\n",
        "\n",
        "def get_agged_session(df):    \n",
        "    event_code = pd.crosstab(df['game_session'], df['event_code'])\n",
        "    event_id = pd.crosstab(df['game_session'], df['event_id'])\n",
        "    event_num_correct = pd.pivot_table(df[(~df['correct'].isna())], index='game_session', columns='event_code', values='num_correct', aggfunc='sum')\n",
        "    event_num_incorrect = pd.pivot_table(df[(~df['correct'].isna())], index='game_session', columns='event_code', values='num_incorrect', aggfunc='sum')\n",
        "    event_accuracy = event_num_correct/(event_num_correct+event_num_incorrect[event_num_correct.columns])\n",
        "    event_accuracy = event_accuracy.add_prefix('accuray_')    \n",
        "    del event_num_correct, event_num_incorrect    \n",
        "    \n",
        "    event_round = pd.pivot_table(df[~df['correct'].isna()], index='game_session', columns='event_code', values='round', aggfunc='max')\n",
        "    event_round = event_round.add_prefix('round_')\n",
        "    \n",
        "    print('max_game_time')    \n",
        "    df['elapsed_time'] = df[['game_session', 'game_time']].groupby('game_session')['game_time'].diff()\n",
        "    game_time = df.groupby('game_session', as_index=False)['elapsed_time'].agg(['mean', 'max']).reset_index()\n",
        "    game_time.columns = ['game_session', 'mean_game_time', 'max_game_time']    \n",
        "    df = df.merge(game_time, on='game_session', how='left')    \n",
        "    event_max_game_time = pd.pivot_table(df, index='game_session', columns='event_code', values='elapsed_time', aggfunc='max')\n",
        "    event_max_game_time = event_max_game_time.add_prefix('max_game_time_')\n",
        "    del df['elapsed_time'] \n",
        "    \n",
        "    print('session_extra_df')\n",
        "    session_extra_df = pd.concat([event_code, event_id, event_accuracy, event_round], 1)\n",
        "    session_extra_df.index.name = 'game_session'\n",
        "    session_extra_df.reset_index(inplace=True)\n",
        "    del event_code, event_id, event_accuracy, event_round\n",
        "    \n",
        "    print('session_df')\n",
        "    session_df = df.drop_duplicates('game_session', keep='last').reset_index(drop=True)\n",
        "    session_df['row_id'] = session_df.index\n",
        "    session_df = session_df.merge(session_extra_df, how='left', on='game_session')\n",
        "    return session_df\n",
        "\n",
        "# installation_idで　groupby\n",
        "def get_train_sample_indices(df):\n",
        "    sample_indices = []\n",
        "    inst_indiecs = []    \n",
        "    df_groups = df.groupby('installation_id').groups\n",
        "    for inst_idx, indices in enumerate(df_groups.values()):\n",
        "        one_df = df.iloc[indices].reset_index(drop=True)\n",
        "        assessment_start_indices = one_df[(one_df['type']=='Assessment')&\n",
        "                                          (one_df['accuracy_group']>=0)\n",
        "                                         ].index\n",
        "        for num, start_index in enumerate(assessment_start_indices):\n",
        "            sample_indices.append( one_df.iloc[:start_index+1]['row_id'].tolist() )\n",
        "            inst_indiecs.append(inst_idx)            \n",
        "    return sample_indices, inst_indiecs\n",
        "\n",
        "# 訓練データをランダムサンプリングする\n",
        "def choose_one(train_samples, train_groups, random_state):    \n",
        "    random.seed(random_state)    \n",
        "    group_dict = {}\n",
        "    for row_id, group in zip(train_samples, train_groups):\n",
        "        if group not in group_dict:\n",
        "            group_dict[group] = []\n",
        "        group_dict[group].append(row_id)\n",
        "    new_train_samples = []    \n",
        "    for v in group_dict.values():        \n",
        "        new_train_samples.append(random.choice(v))         \n",
        "    \n",
        "    return np.array(new_train_samples)\n",
        "\n",
        "class BowlDataset(Dataset):\n",
        "    def __init__(self, cfg, df, sample_indices, aug=0.0, aug_p=0.5, padding_front=True, use_tta=False):\n",
        "        self.cfg = cfg\n",
        "        self.df = df.copy()    \n",
        "        self.sample_indices = sample_indices\n",
        "        self.seq_len = self.cfg.seq_len\n",
        "        self.aug = aug\n",
        "        self.aug_p = aug_p\n",
        "        self.use_tta = use_tta\n",
        "        self.padding_front = padding_front\n",
        "         \n",
        "        self.cate_cols = self.cfg.cate_cols\n",
        "        self.cont_cols = self.cfg.cont_cols\n",
        "        \n",
        "        self.cate_df = self.df[self.cate_cols]\n",
        "        self.cont_df = np.log1p(self.df[self.cont_cols])                \n",
        "        if 'accuracy_group' in self.df:\n",
        "            self.df['num_incorrect'][self.df['num_incorrect']==1] = 0.5\n",
        "            self.df['num_incorrect'][self.df['num_incorrect']>1] = 1.0            \n",
        "            self.df['num_correct'][self.df['num_correct']>1] = 1.0\n",
        "            self.target_df = self.df[TARGET]\n",
        "        else:\n",
        "            self.target_df = None\n",
        "            \n",
        "        if 'accuracy_group_game' in self.df:\n",
        "            self.df['num_incorrect_game'][self.df['num_incorrect_game']==1] = 0.5\n",
        "            self.df['num_incorrect_game'][self.df['num_incorrect_game']>1] = 1.0            \n",
        "            self.df['num_correct_game'][self.df['num_correct_game']>1] = 1.0\n",
        "            self.target_game_df = self.df[GAME_TARGET]\n",
        "        else:\n",
        "            self.target_game_df = None\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        indices = self.sample_indices[idx]\n",
        "        \n",
        "        seq_len = min(self.seq_len, len(indices))\n",
        "        \n",
        "        if self.aug > 0:\n",
        "            if len(indices)>30:\n",
        "                if np.random.binomial(1, self.aug_p) == 1:\n",
        "                    cut_ratio = random.random()\n",
        "                    if cut_ratio > self.aug:\n",
        "                        cut_ratio = self.aug\n",
        "                    #cut_ratio = self.aug\n",
        "                    start_idx = max(int(len(indices)*cut_ratio), 30)\n",
        "                    indices = indices[start_idx:]\n",
        "                    seq_len = min(self.seq_len, len(indices))\n",
        "        \n",
        "        tmp_cate_x = torch.LongTensor(self.cate_df.iloc[indices].values)\n",
        "        cate_x = torch.LongTensor(self.seq_len, len(self.cate_cols)).zero_()\n",
        "        if self.padding_front:\n",
        "            cate_x[-seq_len:] = tmp_cate_x[-seq_len:]\n",
        "        else:\n",
        "            cate_x[:seq_len] = tmp_cate_x[-seq_len:]\n",
        "        \n",
        "        tmp_cont_x = torch.FloatTensor(self.cont_df.iloc[indices].values)\n",
        "        tmp_cont_x[-1] = 0\n",
        "        cont_x = torch.FloatTensor(self.seq_len, len(self.cont_cols)).zero_()\n",
        "        if self.padding_front:            \n",
        "            cont_x[-seq_len:] = tmp_cont_x[-seq_len:]\n",
        "        else:\n",
        "            cont_x[:seq_len] = tmp_cont_x[-seq_len:]\n",
        "        \n",
        "        mask = torch.ByteTensor(self.seq_len).zero_()\n",
        "        if self.padding_front:\n",
        "            mask[-seq_len:] = 1\n",
        "        else:\n",
        "            mask[:seq_len] = 1\n",
        "        \n",
        "        if self.target_df is not None:\n",
        "            target = torch.FloatTensor(self.target_df.iloc[indices[-1]].values)\n",
        "            if target.sum() == 0:                \n",
        "                target = torch.FloatTensor(self.target_game_df.iloc[indices[-1]].values)            \n",
        "        else:\n",
        "            target = 0\n",
        "        \n",
        "        return cate_x, cont_x, mask, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sample_indices)\n",
        "\n",
        "# バリデーションのための予測\n",
        "def validate(valid_loader, model):\n",
        "    # lstmなどのモデルを読み込む\n",
        "    # modelは結局のところクラスになっている。それを実行するための記述らしい。\n",
        "    model.eval()    \n",
        "    \n",
        "    predictions = []\n",
        "    # ground truth data : 正確さや整合性をチェックするためのデータ\n",
        "    groundtruths = []\n",
        "\n",
        "    # testのタプルには3つだが、教師データがあるので4つのタプルになる。\n",
        "    for step, (cate_x, cont_x, mask, y) in enumerate(valid_loader):\n",
        "        \n",
        "        # CFGのクラスにあるdeviceで、cpuに指定している。\n",
        "        cate_x, cont_x, mask = cate_x.to(CFG.device), cont_x.to(CFG.device), mask.to(CFG.device)        \n",
        "        \n",
        "        k = 0.5\n",
        "        # 勾配の計算を初期化している。\n",
        "        with torch.no_grad():\n",
        "            # modelに値を入れると予測結果が吐かれるぽい。predはどんな値？→ReLUなので連続値のはず。\n",
        "            pred = model(cate_x, cont_x, mask)\n",
        "          \n",
        "        # record accuracy 　なぜ一つ目とそれ以外でわけるのか。\n",
        "        pred_y = (1-k)*pred[:, 0] + (k)*compute_acc_gp(pred[:, 1:])\n",
        "        predictions.append(pred_y.detach().cpu())\n",
        "        # 実績値の更新\n",
        "        groundtruths.append(y[:, 0])\n",
        "\n",
        "    predictions = torch.cat(predictions).numpy()\n",
        "    groundtruths = torch.cat(groundtruths).numpy()\n",
        "    \n",
        "    return predictions, groundtruths\n",
        "\n",
        "# 予測結果の1番目を3倍したもの、予測結果の2番目を2倍したものの差分、負であれば0を返す。\n",
        "# グループを予測しているということ？predはReLUの値を線形にしたものなので、連続値が入るはず。\n",
        "def compute_acc_gp(pred):\n",
        "    #batch_size = pred.size(0)\n",
        "    pred = (3*pred[:, 0] - 2*pred[:, 1])    \n",
        "    pred[pred < 0] = 0    \n",
        "    return pred\n",
        "\n",
        "# quadratic weighted kappaの最適化を行い、kappa scoreを返す\n",
        "def get_optimized_kappa_score(predictions, groundtruth):\n",
        "    # 最適化のクラスを呼び出し\n",
        "    optR = OptimizedRounder()\n",
        "    # 目的関数の最小化により係数を計算する\n",
        "    optR.fit(predictions, groundtruth)\n",
        "    # 最小化した係数\n",
        "    coefficients = optR.coefficients()\n",
        "    #print(coefficients)\n",
        "    temp_predictions = predictions.copy()\n",
        "    temp_predictions[temp_predictions < coefficients[0]] = 0\n",
        "    temp_predictions[(coefficients[0]<=temp_predictions)&(temp_predictions< coefficients[1])] = 1\n",
        "    temp_predictions[(coefficients[1]<=temp_predictions)&(temp_predictions< coefficients[2])] = 2\n",
        "    temp_predictions[(coefficients[2]<=temp_predictions)] = 3\n",
        "\n",
        "    # QWKの計算\n",
        "    kappa_score = qwk3(temp_predictions, groundtruth)\n",
        "    return kappa_score, coefficients \n",
        "\n",
        "# QWKを最適化するための閾値を見つける\n",
        "class OptimizedRounder(object):\n",
        "    \"\"\"\n",
        "    An optimizer for rounding thresholds\n",
        "    to maximize Quadratic Weighted Kappa (QWK) score\n",
        "    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.coef_ = 0\n",
        "\n",
        "    def _kappa_loss(self, coef, X, y):\n",
        "        \"\"\"\n",
        "        Get loss according to\n",
        "        using current coefficients\n",
        "        \n",
        "        :param coef: A list of coefficients that will be used for rounding\n",
        "        :param X: The raw predictions\n",
        "        :param y: The ground truth labels\n",
        "        \"\"\"\n",
        "        # coefの次元はどれくらいだろうか？初期値が3次元だったので、3次元。\n",
        "        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
        "\n",
        "        # 閾値をもとにQWKを計算。最小化したいので負値になっている。\n",
        "        return -qwk3(y, X_p)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Optimize rounding thresholds\n",
        "        \n",
        "        :param X: The raw predictions\n",
        "        :param y: The ground truth labels\n",
        "        \"\"\"\n",
        "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
        "        initial_coef = [0.5, 1.5, 2.5]\n",
        "        # scipyのoptimize関数で最小化する。\n",
        "        self.coef_ = optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
        "\n",
        "    def predict(self, X, coef):\n",
        "        \"\"\"\n",
        "        Make predictions with specified thresholds\n",
        "        \n",
        "        :param X: The raw predictions\n",
        "        :param coef: A list of coefficients that will be used for rounding\n",
        "        \"\"\"\n",
        "        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
        "\n",
        "    def coefficients(self):\n",
        "        \"\"\"\n",
        "        Return the optimized coefficients\n",
        "        \"\"\"\n",
        "        return self.coef_['x']\n",
        "\n",
        "# QWKの計算\n",
        "@jit\n",
        "def qwk3(a1, a2, max_rat=3):\n",
        "    assert(len(a1) == len(a2))\n",
        "    a1 = np.asarray(a1, dtype=int)\n",
        "    a2 = np.asarray(a2, dtype=int)\n",
        "\n",
        "    hist1 = np.zeros((max_rat + 1, ))\n",
        "    hist2 = np.zeros((max_rat + 1, ))\n",
        "\n",
        "    o = 0\n",
        "    for k in range(a1.shape[0]):\n",
        "        i, j = a1[k], a2[k]\n",
        "        hist1[i] += 1\n",
        "        hist2[j] += 1\n",
        "        o +=  (i - j) * (i - j)\n",
        "\n",
        "    e = 0\n",
        "    for i in range(max_rat + 1):\n",
        "        for j in range(max_rat + 1):\n",
        "            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n",
        "\n",
        "    e = e / a1.shape[0]\n",
        "\n",
        "    return 1 - o / (e+1e-08)\n",
        "\n",
        "# テストデータに関する予測\n",
        "def test(valid_loader, model):\n",
        "    # lstmなどのモデルを読み込む\n",
        "    # modelは結局のところクラスになっている。それを実行するための記述らしい。\n",
        "    model.eval()    \n",
        "    \n",
        "    predictions = []\n",
        "    # このmaskはBERTの論文にあった、あのマスク？\n",
        "    # valid_loaderって何？torchのDataLoader()のこと。\n",
        "    # enumerateはカウントとタプルを返す\n",
        "    for step, (cate_x, cont_x, mask, _) in enumerate(valid_loader):\n",
        "        \n",
        "        # CFGのクラスにあるdeviceで、cpuに指定している。\n",
        "        cate_x, cont_x, mask = cate_x.to(CFG.device), cont_x.to(CFG.device), mask.to(CFG.device)        \n",
        "        \n",
        "        k = 0.5\n",
        "        # 勾配の計算を初期化している。\n",
        "        with torch.no_grad():\n",
        "            # modelに値を入れると予測結果が吐かれるぽい。classの定義でそうなっていた。\n",
        "            pred = model(cate_x, cont_x, mask)\n",
        "          \n",
        "        # record accuracy\n",
        "        # kで重み付けをしている。ここでは0.5にしている。\n",
        "        # compute_acc_gpは？\n",
        "        pred_y = (1-k)*pred[:, 0] + (k)*compute_acc_gp(pred[:, 1:])\n",
        "        # variable型からtensor型を取り出す際ためにdetachを用いている。\n",
        "        predictions.append(pred_y.detach().cpu())        \n",
        "\n",
        "    # torch.cat()でtensorを連結する\n",
        "    predictions = torch.cat(predictions).numpy()\n",
        "    \n",
        "    return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Itf-LZFm8TZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a7e679f5-fe54-41d3-a03e-43e7f9315fbf"
      },
      "source": [
        "# test_dfは特徴量を前処理して、元データを更新したもの\n",
        "# test_samplesは訓練に使ったサンプルのインデックス\n",
        "# test_groupはinstallation_idのインデックス\n",
        "test_df, test_samples, test_groups = preprocessing(test_df, train_columns, mappers_dict, cate_offset, \n",
        "                        cate_cols, cont_cols, extra_cont_cls)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preprocessing ... \n",
            "generating label ...\n",
            "extract_data_from_event_code ...\n",
            "max_game_time\n",
            "session_extra_df\n",
            "session_df\n",
            "preprocessing ... done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SXNebhmFSps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f206149d-63ed-4654-9f2c-bca2bd3c20b4"
      },
      "source": [
        "CFG.target_size = 3\n",
        "\n",
        "CFG.total_cate_size = cate_offset\n",
        "\n",
        "print(CFG.__dict__)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'__module__': '__main__', 'learning_rate': 0.0001, 'batch_size': 64, 'num_workers': 4, 'print_freq': 100, 'test_freq': 1, 'start_epoch': 0, 'num_train_epochs': 1, 'warmup_steps': 30, 'max_grad_norm': 1000, 'gradient_accumulation_steps': 1, 'weight_decay': 0.01, 'dropout': 0.2, 'emb_size': 100, 'hidden_size': 500, 'nlayers': 2, 'nheads': 8, 'device': 'cpu', 'seed': 7, 'ntta': [0, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6], 'wtta': [0.8, 0.016666666666666663, 0.016666666666666663, 0.016666666666666663, 0.016666666666666663, 0.016666666666666663, 0.016666666666666663, 0.016666666666666663, 0.016666666666666663, 0.016666666666666663, 0.016666666666666663, 0.016666666666666663, 0.016666666666666663], '__dict__': <attribute '__dict__' of 'CFG' objects>, '__weakref__': <attribute '__weakref__' of 'CFG' objects>, '__doc__': None, 'target_size': 3, 'total_cate_size': 53}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg5lmv3QFbOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CFG.cate_cols = cate_cols\n",
        "CFG.cont_cols = cont_cols+extra_cont_cls\n",
        "\n",
        "base_model_path_list = [\n",
        "    ['bowl_v62.pt', [\n",
        "        [1.0, f'/content/drive/Colab Notebooks/Kaggle/b-32_a-TRANSFORMER_e-100_h-500_d-0.2_l-2_hd-10_s-7_len-100_aug-0.5_da-bowl_v62.pt_k-0.pt'],            \n",
        "    ]],\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAj-DvhMIbnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 今回はこちらが使われている。\n",
        "class TransfomerModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        # super() 関数の使い方は super(クラス, インスタンス自身).メソッド名()\n",
        "        # 親クラスのメソッドや変数を呼んだり参照したいケース\n",
        "        super(TransfomerModel, self).__init__()\n",
        "        self.cfg = cfg\n",
        "        cate_col_size = len(cfg.cate_cols)\n",
        "        cont_col_size = len(cfg.cont_cols)\n",
        "        # 分散表現\n",
        "        self.cate_emb = nn.Embedding(cfg.total_cate_size, cfg.emb_size, padding_idx=0)\n",
        "        # 線形と正規化の層\n",
        "        self.cate_proj = nn.Sequential(\n",
        "            nn.Linear(cfg.emb_size*cate_col_size, cfg.hidden_size//2),\n",
        "            nn.LayerNorm(cfg.hidden_size//2),\n",
        "        )\n",
        "        # 線形と正規化の層\n",
        "        self.cont_emb = nn.Sequential(                \n",
        "            nn.Linear(cont_col_size, cfg.hidden_size//2),\n",
        "            nn.LayerNorm(cfg.hidden_size//2),\n",
        "        )\n",
        "        \n",
        "        # BERTの設定\n",
        "        self.config = BertConfig( \n",
        "            3, # not used\n",
        "            hidden_size=cfg.hidden_size,\n",
        "            num_hidden_layers=cfg.nlayers,\n",
        "            num_attention_heads=cfg.nheads,\n",
        "            intermediate_size=cfg.hidden_size,\n",
        "            hidden_dropout_prob=cfg.dropout,\n",
        "            attention_probs_dropout_prob=cfg.dropout,\n",
        "        )\n",
        "        # BERTのエンコーダ\n",
        "        self.encoder = BertEncoder(self.config)        \n",
        "        \n",
        "        # ネットワークを設定\n",
        "        # 線形→正規化→ドロップアウト→ReLU→線形→正規化→ドロップアウト→ReLU→線形\n",
        "        def get_reg():\n",
        "            return nn.Sequential(\n",
        "            nn.Linear(cfg.hidden_size, cfg.hidden_size),\n",
        "            nn.LayerNorm(cfg.hidden_size),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(cfg.hidden_size, cfg.hidden_size),\n",
        "            nn.LayerNorm(cfg.hidden_size),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(cfg.hidden_size, cfg.target_size),            \n",
        "        )        \n",
        "        self.reg_layer = get_reg()\n",
        "        \n",
        "    # 予測結果を返す関数らしい。他のコードでforwardについて記述はされていないので、\n",
        "    # このclassではこの引数を渡せば予測が行われるらしい。\n",
        "    def forward(self, cate_x, cont_x, mask):        \n",
        "        batch_size = cate_x.size(0)\n",
        "        \n",
        "        cate_emb = self.cate_emb(cate_x).view(batch_size, self.cfg.seq_len, -1)\n",
        "        cate_emb = self.cate_proj(cate_emb)     \n",
        "        cont_emb = self.cont_emb(cont_x)\n",
        "        \n",
        "        seq_emb = torch.cat([cate_emb, cont_emb], 2)\n",
        "        \n",
        "        extended_attention_mask = mask.unsqueeze(1).unsqueeze(2)\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype) # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "        head_mask = [None] * self.config.num_hidden_layers\n",
        "        \n",
        "        encoded_layers = self.encoder(seq_emb, extended_attention_mask, head_mask=head_mask)\n",
        "        sequence_output = encoded_layers[-1]\n",
        "        sequence_output = sequence_output[:, -1]\n",
        "        \n",
        "        # get_regで作成したネットワークに従って予測値を出力（ReLU型の後に線形なので連続値）\n",
        "        pred_y = self.reg_layer(sequence_output)\n",
        "        return pred_y\n",
        "\n",
        "class LSTMATTNModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super(LSTMATTNModel, self).__init__()\n",
        "        self.cfg = cfg\n",
        "        cate_col_size = len(cfg.cate_cols)\n",
        "        cont_col_size = len(cfg.cont_cols)\n",
        "        self.cate_emb = nn.Embedding(cfg.total_cate_size, cfg.emb_size, padding_idx=0)        \n",
        "        self.cate_proj = nn.Sequential(\n",
        "            nn.Linear(cfg.emb_size*cate_col_size, cfg.hidden_size//2),\n",
        "            nn.LayerNorm(cfg.hidden_size//2),\n",
        "        )        \n",
        "        self.cont_emb = nn.Sequential(                \n",
        "            nn.Linear(cont_col_size, cfg.hidden_size//2),\n",
        "            nn.LayerNorm(cfg.hidden_size//2),\n",
        "        )\n",
        "        \n",
        "        self.encoder = nn.LSTM(cfg.hidden_size, \n",
        "                            cfg.hidden_size, 1, dropout=cfg.dropout, batch_first=True)\n",
        "        \n",
        "        self.config = BertConfig( \n",
        "            3, # not used\n",
        "            hidden_size=cfg.hidden_size,\n",
        "            num_hidden_layers=1,\n",
        "            num_attention_heads=cfg.nheads,\n",
        "            intermediate_size=cfg.hidden_size,\n",
        "            hidden_dropout_prob=cfg.dropout,\n",
        "            attention_probs_dropout_prob=cfg.dropout,\n",
        "        )\n",
        "        self.attn = BertEncoder(self.config)                 \n",
        "        \n",
        "        def get_reg():\n",
        "            return nn.Sequential(\n",
        "            nn.Linear(cfg.hidden_size, cfg.hidden_size),\n",
        "            nn.LayerNorm(cfg.hidden_size),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(cfg.hidden_size, cfg.hidden_size),\n",
        "            nn.LayerNorm(cfg.hidden_size),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(cfg.hidden_size, cfg.target_size),            \n",
        "        )           \n",
        "        self.reg_layer = get_reg()\n",
        "        \n",
        "    def forward(self, cate_x, cont_x, mask):        \n",
        "        batch_size = cate_x.size(0)\n",
        "        \n",
        "        cate_emb = self.cate_emb(cate_x).view(batch_size, self.cfg.seq_len, -1)\n",
        "        cate_emb = self.cate_proj(cate_emb) \n",
        "        cont_emb = self.cont_emb(cont_x)\n",
        "        \n",
        "        seq_emb = torch.cat([cate_emb, cont_emb], 2)        \n",
        "        \n",
        "        output, _ = self.encoder(seq_emb)\n",
        "        \n",
        "        extended_attention_mask = mask.unsqueeze(1).unsqueeze(2)\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype) # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "        head_mask = [None] * self.config.num_hidden_layers\n",
        "        \n",
        "        encoded_layers = self.attn(output, extended_attention_mask, head_mask=head_mask)        \n",
        "        sequence_output = encoded_layers[-1]\n",
        "        sequence_output = sequence_output[:, -1]\n",
        "        pred_y = self.reg_layer(sequence_output)\n",
        "        return pred_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXNyyKptHeUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################\n",
        "# find the coefficients\n",
        "################################################\n",
        "rand_seed_list = [7, 77, 777, 1, 2]\n",
        "#rand_seed_list = [110798, 497274, 885651, 673327, 599183, 272713, 582394, 180043, 855725, 932850]    \n",
        "sum_coefficients = 0\n",
        "sum_cnt = 0\n",
        "\n",
        "# クラスをdict形式で持つ\n",
        "ENCODERS = {    \n",
        "    'TRANSFORMER':TransfomerModel,\n",
        "    'LSTMATTN':LSTMATTNModel,\n",
        "}\n",
        "\n",
        "TARGET = ['accuracy_group', 'num_correct', 'num_incorrect']\n",
        "GAME_TARGET = ['accuracy_group_game', 'num_correct_game', 'num_incorrect_game']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaJw9tpmHjHN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "6ed720e0-f396-4e02-b1f2-0f11bdddc7ea"
      },
      "source": [
        "# ここでの繰り返しではQWKの閾値を計算を行う。\n",
        "for _, base_model_paths in base_model_path_list:\n",
        "  for model_w, base_model_path in base_model_paths: \n",
        "\n",
        "    path = base_model_path.split('/')[-1]\n",
        "    path = path.replace('bowl_', '')\n",
        "    cfg_dict = dict([tok.split('-') for tok in path.split('_')])\n",
        "    CFG.encoder = cfg_dict['a']\n",
        "    CFG.seq_len = int(cfg_dict['len'])\n",
        "    CFG.emb_size = int(cfg_dict['e'])\n",
        "    CFG.hidden_size = int(cfg_dict['h'])\n",
        "    CFG.nlayers = int(cfg_dict['l'])\n",
        "    CFG.nheads = int(cfg_dict['hd'])\n",
        "    CFG.seed = int(cfg_dict['s'])\n",
        "    CFG.data_seed = int(cfg_dict['s'])\n",
        "    print(path)\n",
        "\n",
        "    for k in range(5):\n",
        "      # エンコーダを指定して、CFGのパラメータを設定？　今回はTRANSFORMERを使っている。\n",
        "      # このモデルをprintするとネットワーク層が描かれる。\n",
        "      model = ENCODERS[CFG.encoder](CFG)\n",
        "      # iterationごとのモデルのパス\n",
        "      model_path = base_model_path.replace('k-0', f'k-{k}')\n",
        "\n",
        "      # 学習済みのモデルの呼び出し\n",
        "      checkpoint = torch.load(model_path, map_location=CFG.device)\n",
        "\n",
        "      # Loads a model’s parameter dictionary using a deserialized state_dict\n",
        "      model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "      model.to(CFG.device)\n",
        "      print(\"=> loaded checkpoint '{}' (epoch {})\".format(model_path, checkpoint['epoch']))\n",
        "\n",
        "      \n",
        "      for rand_seed in rand_seed_list:\n",
        "        # 557個ずつインデックスを選んでいる\n",
        "        chosen_samples = choose_one(test_samples, test_groups, random_state=rand_seed)\n",
        "        predictions = 0\n",
        "\n",
        "        # CFG.wttaやCFG.nttaはパラメータのセット？\n",
        "        for w, tta in zip(CFG.wtta, CFG.ntta):\n",
        "            padding_front = False if CFG.encoder=='LSTM' else True\n",
        "            valid_db = BowlDataset(CFG,\n",
        "                                    test_df,\n",
        "                                    chosen_samples,\n",
        "                                    aug=tta, aug_p=1.0, \n",
        "                                    padding_front=padding_front,\n",
        "                                    use_tta=True)\n",
        "            \n",
        "            valid_loader = DataLoader(\n",
        "                    valid_db, batch_size=CFG.batch_size, shuffle=False,\n",
        "                    num_workers=CFG.num_workers, pin_memory=True)\n",
        "            \n",
        "            # クロスバリデーションで予測値と実績値を返す\n",
        "            prediction, groundtruths = validate(valid_loader, model)\n",
        "\n",
        "            # 予測に重みをかけあわせている\n",
        "            predictions += w*prediction\n",
        "\n",
        "        try:\n",
        "            # QWKの計算\n",
        "            valid_kappa, valid_coefficients = get_optimized_kappa_score(predictions, groundtruths)\n",
        "            print(f'k[{k}]-s2[{rand_seed}]: valid_kappa:{valid_kappa} - {valid_coefficients}') \n",
        "            sum_coefficients += np.array(valid_coefficients)\n",
        "            sum_cnt += 1\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print(f'k[{k}]-s2[{rand_seed}]: valid_kappa: Failed!')\n",
        "            pass\n",
        "      del model"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b-32_a-TRANSFORMER_e-100_h-500_d-0.2_l-2_hd-10_s-7_len-100_aug-0.5_da-v62.pt_k-0.pt\n",
            "=> loaded checkpoint '/content/drive/Colab Notebooks/Kaggle/b-32_a-TRANSFORMER_e-100_h-500_d-0.2_l-2_hd-10_s-7_len-100_aug-0.5_da-bowl_v62.pt_k-0.pt' (epoch 9)\n",
            "k[0]-s2[7]: valid_kappa:0.5518188057683471 - [0.50470062 1.64539402 2.21933667]\n",
            "k[0]-s2[77]: valid_kappa:0.5620423930741866 - [0.49800481 1.65287271 2.20986244]\n",
            "k[0]-s2[777]: valid_kappa:0.5605541152186521 - [0.48896893 1.64579143 2.21183745]\n",
            "k[0]-s2[1]: valid_kappa:0.5233320533840617 - [0.51969384 1.42335338 2.34570201]\n",
            "k[0]-s2[2]: valid_kappa:0.5618052862204765 - [0.5154613  1.6456123  2.20715851]\n",
            "=> loaded checkpoint '/content/drive/Colab Notebooks/Kaggle/b-32_a-TRANSFORMER_e-100_h-500_d-0.2_l-2_hd-10_s-7_len-100_aug-0.5_da-bowl_v62.pt_k-1.pt' (epoch 3)\n",
            "k[1]-s2[7]: valid_kappa:0.5707085560171881 - [0.51319162 1.52085867 2.2257029 ]\n",
            "k[1]-s2[77]: valid_kappa:0.5382737680673599 - [0.50380652 1.54697342 2.40895508]\n",
            "k[1]-s2[777]: valid_kappa:0.5647968531121399 - [0.50763118 1.53094411 2.22745841]\n",
            "k[1]-s2[1]: valid_kappa:0.5154798428435388 - [0.52974658 1.63821976 2.22409698]\n",
            "k[1]-s2[2]: valid_kappa:0.5609916190883699 - [0.51178423 1.52972422 2.22475119]\n",
            "=> loaded checkpoint '/content/drive/Colab Notebooks/Kaggle/b-32_a-TRANSFORMER_e-100_h-500_d-0.2_l-2_hd-10_s-7_len-100_aug-0.5_da-bowl_v62.pt_k-2.pt' (epoch 3)\n",
            "k[2]-s2[7]: valid_kappa:0.5586107584450379 - [0.58366341 1.49904835 2.16012946]\n",
            "k[2]-s2[77]: valid_kappa:0.5490730141526271 - [0.55555556 1.5125     2.16666667]\n",
            "k[2]-s2[777]: valid_kappa:0.5459092911886879 - [0.52302812 1.60807613 2.11325446]\n",
            "k[2]-s2[1]: valid_kappa:0.5163762382251824 - [0.56559285 1.48159722 2.16591114]\n",
            "k[2]-s2[2]: valid_kappa:0.5442048612878206 - [0.56609252 1.47851964 2.17583617]\n",
            "=> loaded checkpoint '/content/drive/Colab Notebooks/Kaggle/b-32_a-TRANSFORMER_e-100_h-500_d-0.2_l-2_hd-10_s-7_len-100_aug-0.5_da-bowl_v62.pt_k-3.pt' (epoch 9)\n",
            "k[3]-s2[7]: valid_kappa:0.5555430451286942 - [0.54782442 1.5451165  2.17474867]\n",
            "k[3]-s2[77]: valid_kappa:0.5543845896716681 - [0.53189515 1.65071373 2.15503901]\n",
            "k[3]-s2[777]: valid_kappa:0.5643206857962049 - [0.54656747 1.55450579 2.15532757]\n",
            "k[3]-s2[1]: valid_kappa:0.5258294487625504 - [0.54444444 1.60833333 2.15277778]\n",
            "k[3]-s2[2]: valid_kappa:0.5511780568806233 - [0.54444444 1.54166667 2.15277778]\n",
            "=> loaded checkpoint '/content/drive/Colab Notebooks/Kaggle/b-32_a-TRANSFORMER_e-100_h-500_d-0.2_l-2_hd-10_s-7_len-100_aug-0.5_da-bowl_v62.pt_k-4.pt' (epoch 7)\n",
            "k[4]-s2[7]: valid_kappa:0.5717886737808346 - [0.54214327 1.60350444 2.21664494]\n",
            "k[4]-s2[77]: valid_kappa:0.5548439511181985 - [0.55725862 1.4488868  2.21679732]\n",
            "k[4]-s2[777]: valid_kappa:0.5713982108948805 - [0.54605397 1.49592748 2.23637228]\n",
            "k[4]-s2[1]: valid_kappa:0.5279953702780793 - [0.52932099 1.49050926 2.29783951]\n",
            "k[4]-s2[2]: valid_kappa:0.521633357901685 - [0.60278357 1.43427128 1.90477784]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6koQrbyD6ei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# installation_idごとのindexを返している\n",
        "test_samples = list(test_df.groupby(['installation_id']).groups.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7vfrvsQGDt2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4342e209-bd85-4323-89ce-bcb0321744a5"
      },
      "source": [
        "# accuracy groupの閾値はiterationにより計算したものを平均とったものと、固定で指定したものとで半々で重み付けしている。\n",
        "coefficients = 0.5*sum_coefficients/sum_cnt + 0.5*np.array([0.53060865, 1.66266655, 2.31145611])       \n",
        "print('=======================================')\n",
        "print(f'coefficients - {coefficients}')\n",
        "print('=======================================')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=======================================\n",
            "coefficients - [0.53289749 1.60599169 2.2547233 ]\n",
            "=======================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vZay7fwGPWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.seed(CFG.seed)\n",
        "\n",
        "submission_df = test_df.groupby('installation_id').tail(1)[['installation_id']]\n",
        "submission_df['accuracy_group'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4bGYe8_G_79",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "019967ea-d309-451b-ac79-da5e123feead"
      },
      "source": [
        "submission_df.tail(5)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>installation_id</th>\n",
              "      <th>accuracy_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28364</th>\n",
              "      <td>fee254cf</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28381</th>\n",
              "      <td>ff57e602</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28420</th>\n",
              "      <td>ffc73fb2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28439</th>\n",
              "      <td>ffe00ca8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28444</th>\n",
              "      <td>ffe774cc</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      installation_id  accuracy_group\n",
              "28364        fee254cf               0\n",
              "28381        ff57e602               0\n",
              "28420        ffc73fb2               0\n",
              "28439        ffe00ca8               0\n",
              "28444        ffe774cc               0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1Z7jOruHN9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c8e611e0-5b7a-4660-f363-d16d5199fa51"
      },
      "source": [
        "# ここでは予測を行っている。\n",
        "for _, base_model_paths in base_model_path_list:\n",
        "  for model_w, base_model_path in base_model_paths:\n",
        "    # モデルのパス\n",
        "    path = base_model_path.split('/')[-1]\n",
        "    path = path.replace('bowl_', '')\n",
        "\n",
        "    cfg_dict = dict([tok.split('-') for tok in path.split('_')])\n",
        "    # ファイル名に引数が指定されているので、それらをクラスに当てはめていく。\n",
        "    CFG.encoder = cfg_dict['a']\n",
        "    CFG.seq_len = int(cfg_dict['len'])\n",
        "    CFG.emb_size = int(cfg_dict['e'])\n",
        "    CFG.hidden_size = int(cfg_dict['h'])\n",
        "    CFG.nlayers = int(cfg_dict['l'])\n",
        "    CFG.nheads = int(cfg_dict['hd'])\n",
        "    CFG.seed = int(cfg_dict['s'])\n",
        "    CFG.data_seed = int(cfg_dict['s'])\n",
        "\n",
        "    for k in range(5):\n",
        "      # あるモデルに関して、CFGで定義したパラメータ\n",
        "      # printしてみるとネットワーク層が描かれている\n",
        "      model = ENCODERS[CFG.encoder](CFG)\n",
        "      model_path = base_model_path.replace('k-0', f'k-{k}')\n",
        "\n",
        "      # 学習済みのモデルの呼び出し\n",
        "      checkpoint = torch.load(model_path, map_location=CFG.device)\n",
        "\n",
        "      model.load_state_dict(checkpoint['state_dict'])\n",
        "      model.to(CFG.device)\n",
        "      print(\"=> loaded checkpoint '{}' (epoch {})\".format(model_path, checkpoint['epoch']))\n",
        "\n",
        "      for w, tta in zip(CFG.wtta, CFG.ntta):\n",
        "          padding_front = False if CFG.encoder=='LSTM' else True\n",
        "          # 扱うデータ自体はvalidationの時と同じ。\n",
        "          valid_db = BowlDataset(CFG, test_df, test_samples, aug=tta, aug_p=1.0, \n",
        "                                  padding_front=padding_front, use_tta=True)\n",
        "          valid_loader = DataLoader(\n",
        "                  valid_db, batch_size=CFG.batch_size, shuffle=False,\n",
        "                  num_workers=CFG.num_workers, pin_memory=True)\n",
        "          # 予測\n",
        "          predictions = test(valid_loader, model)\n",
        "          # モデルが5つあるので、5で割って単純平均にしている。\n",
        "          submission_df['accuracy_group'] += w*predictions*model_w*(1/5)\n",
        "      del model  "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> loaded checkpoint '/content/drive/Colab Notebooks/Kaggle/b-32_a-TRANSFORMER_e-100_h-500_d-0.2_l-2_hd-10_s-7_len-100_aug-0.5_da-bowl_v62.pt_k-0.pt' (epoch 9)\n",
            "=> loaded checkpoint '/content/drive/Colab Notebooks/Kaggle/b-32_a-TRANSFORMER_e-100_h-500_d-0.2_l-2_hd-10_s-7_len-100_aug-0.5_da-bowl_v62.pt_k-1.pt' (epoch 3)\n",
            "=> loaded checkpoint '/content/drive/Colab Notebooks/Kaggle/b-32_a-TRANSFORMER_e-100_h-500_d-0.2_l-2_hd-10_s-7_len-100_aug-0.5_da-bowl_v62.pt_k-2.pt' (epoch 3)\n",
            "=> loaded checkpoint '/content/drive/Colab Notebooks/Kaggle/b-32_a-TRANSFORMER_e-100_h-500_d-0.2_l-2_hd-10_s-7_len-100_aug-0.5_da-bowl_v62.pt_k-3.pt' (epoch 9)\n",
            "=> loaded checkpoint '/content/drive/Colab Notebooks/Kaggle/b-32_a-TRANSFORMER_e-100_h-500_d-0.2_l-2_hd-10_s-7_len-100_aug-0.5_da-bowl_v62.pt_k-4.pt' (epoch 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JsGxwb0KHpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# クロスバリデーションで求めた閾値を用いてaccuracy_groupのデータを作成\n",
        "def compute_th_acc_gp(temp, coef):\n",
        "    temp[temp < coef[0]] = 0\n",
        "    temp[(coef[0]<=temp)&(temp< coef[1])] = 1\n",
        "    temp[(coef[1]<=temp)&(temp< coef[2])] = 2\n",
        "    temp[(coef[2]<=temp)] = 3    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4F12NKGJwIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_df['accuracy_group'] /= len(base_model_path_list)\n",
        "\n",
        "# QWKの閾値の計算を推定した結果をここで使っている。\n",
        "# クロスバリデーションで求めた閾値を用いてaccuracy_groupのデータを作成\n",
        "compute_th_acc_gp(submission_df['accuracy_group'], coefficients) \n",
        "\n",
        "submission_df['accuracy_group'] = submission_df['accuracy_group'].astype(int)\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLQKxOjKlzXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq7ESdh9XsSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}