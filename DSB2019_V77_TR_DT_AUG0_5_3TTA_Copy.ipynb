{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSB2019_V77_TR_DT_AUG0.5_3TTA_Copy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCkOS07qxp1053lDaCeOLM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KamonohashiPerry/kaggle/blob/master/DSB2019_V77_TR_DT_AUG0_5_3TTA_Copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDlQjo_pRAAH",
        "colab_type": "text"
      },
      "source": [
        "## PyTorchのインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyhIzO_0Qquj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install http://download.pytorch.org/whl/cu80/torch-0.4.0-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKh4BJaRQ2Kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nln6uUt4VUuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install pytorch-transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rXmJqHWazqU",
        "colab_type": "text"
      },
      "source": [
        "## Reference\n",
        "https://www.kaggle.com/limerobot/dsb2019-v77-tr-dt-aug0-5-3tta/comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdzOK0pGRntL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import gc\n",
        "import time\n",
        "import random\n",
        "\n",
        "from scipy import optimize\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from pytorch_transformers.modeling_bert import BertConfig, BertEncoder\n",
        "\n",
        "\n",
        "# 関数やメソッドの引数の一部をある値に固定して新しいオブジェクトを作れる\n",
        "from functools import partial\n",
        "# 高速化のため\n",
        "from numba import jit\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WcgZ3pQR61i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TARGET = ['accuracy_group', 'num_correct', 'num_incorrect']\n",
        "GAME_TARGET = ['accuracy_group_game', 'num_correct_game', 'num_incorrect_game']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuxqbwY1WF4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BowlDataset(Dataset):\n",
        "    def __init__(self, cfg, df, sample_indices, aug=0.0, aug_p=0.5, padding_front=True, use_tta=False):\n",
        "        self.cfg = cfg\n",
        "        self.df = df.copy()    \n",
        "        self.sample_indices = sample_indices\n",
        "        self.seq_len = self.cfg.seq_len\n",
        "        self.aug = aug\n",
        "        self.aug_p = aug_p\n",
        "        self.use_tta = use_tta\n",
        "        self.padding_front = padding_front\n",
        "         \n",
        "        self.cate_cols = self.cfg.cate_cols\n",
        "        self.cont_cols = self.cfg.cont_cols\n",
        "        \n",
        "        self.cate_df = self.df[self.cate_cols]\n",
        "        self.cont_df = np.log1p(self.df[self.cont_cols])                \n",
        "        if 'accuracy_group' in self.df:\n",
        "            self.df['num_incorrect'][self.df['num_incorrect']==1] = 0.5\n",
        "            self.df['num_incorrect'][self.df['num_incorrect']>1] = 1.0            \n",
        "            self.df['num_correct'][self.df['num_correct']>1] = 1.0\n",
        "            self.target_df = self.df[TARGET]\n",
        "        else:\n",
        "            self.target_df = None\n",
        "            \n",
        "        if 'accuracy_group_game' in self.df:\n",
        "            self.df['num_incorrect_game'][self.df['num_incorrect_game']==1] = 0.5\n",
        "            self.df['num_incorrect_game'][self.df['num_incorrect_game']>1] = 1.0            \n",
        "            self.df['num_correct_game'][self.df['num_correct_game']>1] = 1.0\n",
        "            self.target_game_df = self.df[GAME_TARGET]\n",
        "        else:\n",
        "            self.target_game_df = None\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        indices = self.sample_indices[idx]\n",
        "        \n",
        "        seq_len = min(self.seq_len, len(indices))\n",
        "        \n",
        "        if self.aug > 0:\n",
        "            if len(indices)>30:\n",
        "                if np.random.binomial(1, self.aug_p) == 1:\n",
        "                    cut_ratio = random.random()\n",
        "                    if cut_ratio > self.aug:\n",
        "                        cut_ratio = self.aug\n",
        "                    #cut_ratio = self.aug\n",
        "                    start_idx = max(int(len(indices)*cut_ratio), 30)\n",
        "                    indices = indices[start_idx:]\n",
        "                    seq_len = min(self.seq_len, len(indices))\n",
        "        \n",
        "        tmp_cate_x = torch.LongTensor(self.cate_df.iloc[indices].values)\n",
        "        cate_x = torch.LongTensor(self.seq_len, len(self.cate_cols)).zero_()\n",
        "        if self.padding_front:\n",
        "            cate_x[-seq_len:] = tmp_cate_x[-seq_len:]\n",
        "        else:\n",
        "            cate_x[:seq_len] = tmp_cate_x[-seq_len:]\n",
        "        \n",
        "        tmp_cont_x = torch.FloatTensor(self.cont_df.iloc[indices].values)\n",
        "        tmp_cont_x[-1] = 0\n",
        "        cont_x = torch.FloatTensor(self.seq_len, len(self.cont_cols)).zero_()\n",
        "        if self.padding_front:            \n",
        "            cont_x[-seq_len:] = tmp_cont_x[-seq_len:]\n",
        "        else:\n",
        "            cont_x[:seq_len] = tmp_cont_x[-seq_len:]\n",
        "        \n",
        "        mask = torch.ByteTensor(self.seq_len).zero_()\n",
        "        if self.padding_front:\n",
        "            mask[-seq_len:] = 1\n",
        "        else:\n",
        "            mask[:seq_len] = 1\n",
        "        \n",
        "        if self.target_df is not None:\n",
        "            target = torch.FloatTensor(self.target_df.iloc[indices[-1]].values)\n",
        "            if target.sum() == 0:                \n",
        "                target = torch.FloatTensor(self.target_game_df.iloc[indices[-1]].values)            \n",
        "        else:\n",
        "            target = 0\n",
        "        \n",
        "        return cate_x, cont_x, mask, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sample_indices)\n",
        "\n",
        "\n",
        "class TransfomerModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super(TransfomerModel, self).__init__()\n",
        "        self.cfg = cfg\n",
        "        cate_col_size = len(cfg.cate_cols)\n",
        "        cont_col_size = len(cfg.cont_cols)\n",
        "        # 分散表現\n",
        "        self.cate_emb = nn.Embedding(cfg.total_cate_size, cfg.emb_size, padding_idx=0)\n",
        "        # 線形と正規化の層\n",
        "        self.cate_proj = nn.Sequential(\n",
        "            nn.Linear(cfg.emb_size*cate_col_size, cfg.hidden_size//2),\n",
        "            nn.LayerNorm(cfg.hidden_size//2),\n",
        "        )\n",
        "        # 線形と正規化の層\n",
        "        self.cont_emb = nn.Sequential(                \n",
        "            nn.Linear(cont_col_size, cfg.hidden_size//2),\n",
        "            nn.LayerNorm(cfg.hidden_size//2),\n",
        "        )\n",
        "        \n",
        "        # BERTの設定\n",
        "        self.config = BertConfig( \n",
        "            3, # not used\n",
        "            hidden_size=cfg.hidden_size,\n",
        "            num_hidden_layers=cfg.nlayers,\n",
        "            num_attention_heads=cfg.nheads,\n",
        "            intermediate_size=cfg.hidden_size,\n",
        "            hidden_dropout_prob=cfg.dropout,\n",
        "            attention_probs_dropout_prob=cfg.dropout,\n",
        "        )\n",
        "        # BERTのエンコーダ\n",
        "        self.encoder = BertEncoder(self.config)        \n",
        "        \n",
        "        # ネットワークを設定\n",
        "        # 線形→正規化→ドロップアウト→ReLU→線形→正規化→ドロップアウト→ReLU→線形\n",
        "        def get_reg():\n",
        "            return nn.Sequential(\n",
        "            nn.Linear(cfg.hidden_size, cfg.hidden_size),\n",
        "            nn.LayerNorm(cfg.hidden_size),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(cfg.hidden_size, cfg.hidden_size),\n",
        "            nn.LayerNorm(cfg.hidden_size),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(cfg.hidden_size, cfg.target_size),            \n",
        "        )        \n",
        "        self.reg_layer = get_reg()\n",
        "        \n",
        "    # 予測結果を返す関数らしい。他のコードでforwardについて記述はされていないので、\n",
        "    # このclassではこの引数を渡せば予測が行われるらしい。\n",
        "    def forward(self, cate_x, cont_x, mask):        \n",
        "        batch_size = cate_x.size(0)\n",
        "        \n",
        "        cate_emb = self.cate_emb(cate_x).view(batch_size, self.cfg.seq_len, -1)\n",
        "        cate_emb = self.cate_proj(cate_emb)     \n",
        "        cont_emb = self.cont_emb(cont_x)\n",
        "        \n",
        "        seq_emb = torch.cat([cate_emb, cont_emb], 2)\n",
        "        \n",
        "        extended_attention_mask = mask.unsqueeze(1).unsqueeze(2)\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype) # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "        head_mask = [None] * self.config.num_hidden_layers\n",
        "        \n",
        "        encoded_layers = self.encoder(seq_emb, extended_attention_mask, head_mask=head_mask)\n",
        "        sequence_output = encoded_layers[-1]\n",
        "        sequence_output = sequence_output[:, -1]\n",
        "        \n",
        "        pred_y = self.reg_layer(sequence_output)\n",
        "        return pred_y\n",
        "\n",
        "    \n",
        "class LSTMATTNModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super(LSTMATTNModel, self).__init__()\n",
        "        self.cfg = cfg\n",
        "        cate_col_size = len(cfg.cate_cols)\n",
        "        cont_col_size = len(cfg.cont_cols)\n",
        "        self.cate_emb = nn.Embedding(cfg.total_cate_size, cfg.emb_size, padding_idx=0)        \n",
        "        self.cate_proj = nn.Sequential(\n",
        "            nn.Linear(cfg.emb_size*cate_col_size, cfg.hidden_size//2),\n",
        "            nn.LayerNorm(cfg.hidden_size//2),\n",
        "        )        \n",
        "        self.cont_emb = nn.Sequential(                \n",
        "            nn.Linear(cont_col_size, cfg.hidden_size//2),\n",
        "            nn.LayerNorm(cfg.hidden_size//2),\n",
        "        )\n",
        "        \n",
        "        self.encoder = nn.LSTM(cfg.hidden_size, \n",
        "                            cfg.hidden_size, 1, dropout=cfg.dropout, batch_first=True)\n",
        "        \n",
        "        self.config = BertConfig( \n",
        "            3, # not used\n",
        "            hidden_size=cfg.hidden_size,\n",
        "            num_hidden_layers=1,\n",
        "            num_attention_heads=cfg.nheads,\n",
        "            intermediate_size=cfg.hidden_size,\n",
        "            hidden_dropout_prob=cfg.dropout,\n",
        "            attention_probs_dropout_prob=cfg.dropout,\n",
        "        )\n",
        "        self.attn = BertEncoder(self.config)                 \n",
        "        \n",
        "        def get_reg():\n",
        "            return nn.Sequential(\n",
        "            nn.Linear(cfg.hidden_size, cfg.hidden_size),\n",
        "            nn.LayerNorm(cfg.hidden_size),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(cfg.hidden_size, cfg.hidden_size),\n",
        "            nn.LayerNorm(cfg.hidden_size),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(cfg.hidden_size, cfg.target_size),            \n",
        "        )           \n",
        "        self.reg_layer = get_reg()\n",
        "        \n",
        "    def forward(self, cate_x, cont_x, mask):        \n",
        "        batch_size = cate_x.size(0)\n",
        "        \n",
        "        cate_emb = self.cate_emb(cate_x).view(batch_size, self.cfg.seq_len, -1)\n",
        "        cate_emb = self.cate_proj(cate_emb) \n",
        "        cont_emb = self.cont_emb(cont_x)\n",
        "        \n",
        "        seq_emb = torch.cat([cate_emb, cont_emb], 2)        \n",
        "        \n",
        "        output, _ = self.encoder(seq_emb)\n",
        "        \n",
        "        extended_attention_mask = mask.unsqueeze(1).unsqueeze(2)\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype) # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "        head_mask = [None] * self.config.num_hidden_layers\n",
        "        \n",
        "        encoded_layers = self.attn(output, extended_attention_mask, head_mask=head_mask)        \n",
        "        sequence_output = encoded_layers[-1]\n",
        "        sequence_output = sequence_output[:, -1]\n",
        "        pred_y = self.reg_layer(sequence_output)\n",
        "        return pred_y\n",
        "\n",
        "\n",
        "\n",
        "# クラスをdict形式で持つ\n",
        "ENCODERS = {    \n",
        "    'TRANSFORMER':TransfomerModel,\n",
        "    'LSTMATTN':LSTMATTNModel,\n",
        "}\n",
        "\n",
        "\n",
        "def replace_4110_4100(df):\n",
        "    rep_code4110_bool = (df['title']=='Bird Measurer (Assessment)')&(df['event_code']==4110)\n",
        "    rep_code4100_bool = (df['title']=='Bird Measurer (Assessment)')&(df['event_code']==4100)\n",
        "    df['event_code'][rep_code4110_bool] = 4100\n",
        "    df['event_code'][rep_code4100_bool] = 5110\n",
        "\n",
        "\n",
        "def get_agged_session(df):    \n",
        "    event_code = pd.crosstab(df['game_session'], df['event_code'])\n",
        "    event_id = pd.crosstab(df['game_session'], df['event_id'])\n",
        "    event_num_correct = pd.pivot_table(df[(~df['correct'].isna())], index='game_session', columns='event_code', values='num_correct', aggfunc='sum')\n",
        "    event_num_incorrect = pd.pivot_table(df[(~df['correct'].isna())], index='game_session', columns='event_code', values='num_incorrect', aggfunc='sum')\n",
        "    event_accuracy = event_num_correct/(event_num_correct+event_num_incorrect[event_num_correct.columns])\n",
        "    event_accuracy = event_accuracy.add_prefix('accuray_')    \n",
        "    del event_num_correct, event_num_incorrect    \n",
        "    \n",
        "    event_round = pd.pivot_table(df[~df['correct'].isna()], index='game_session', columns='event_code', values='round', aggfunc='max')\n",
        "    event_round = event_round.add_prefix('round_')\n",
        "    \n",
        "    print('max_game_time')    \n",
        "    df['elapsed_time'] = df[['game_session', 'game_time']].groupby('game_session')['game_time'].diff()\n",
        "    game_time = df.groupby('game_session', as_index=False)['elapsed_time'].agg(['mean', 'max']).reset_index()\n",
        "    game_time.columns = ['game_session', 'mean_game_time', 'max_game_time']    \n",
        "    df = df.merge(game_time, on='game_session', how='left')    \n",
        "    event_max_game_time = pd.pivot_table(df, index='game_session', columns='event_code', values='elapsed_time', aggfunc='max')\n",
        "    event_max_game_time = event_max_game_time.add_prefix('max_game_time_')\n",
        "    del df['elapsed_time'] \n",
        "    \n",
        "    print('session_extra_df')\n",
        "    session_extra_df = pd.concat([event_code, event_id, event_accuracy, event_round], 1)\n",
        "    session_extra_df.index.name = 'game_session'\n",
        "    session_extra_df.reset_index(inplace=True)\n",
        "    del event_code, event_id, event_accuracy, event_round\n",
        "    \n",
        "    print('session_df')\n",
        "    session_df = df.drop_duplicates('game_session', keep='last').reset_index(drop=True)\n",
        "    session_df['row_id'] = session_df.index\n",
        "    session_df = session_df.merge(session_extra_df, how='left', on='game_session')\n",
        "    return session_df\n",
        "\n",
        "def gen_label(df):\n",
        "    num_corrects = []\n",
        "    for inst_id, one_df in df.groupby('installation_id'):\n",
        "        one_df = one_df[(one_df['type']=='Assessment')&(one_df['event_code']==4100)]\n",
        "        for game_session, title_df in one_df.groupby('game_session'):            \n",
        "            num_correct = title_df['event_data'].str.contains('\"correct\":true').sum()\n",
        "            num_incorrect = title_df['event_data'].str.contains('\"correct\":false').sum()            \n",
        "            num_corrects.append([inst_id, game_session, num_correct, num_incorrect])\n",
        "    label_df = pd.DataFrame(num_corrects, columns=['installation_id', 'game_session', 'num_correct', 'num_incorrect'])\n",
        "    label_df['accuracy'] = label_df['num_correct'] / (label_df['num_correct']+label_df['num_incorrect'])\n",
        "    label_df['accuracy_group'] = 3\n",
        "    label_df['accuracy_group'][label_df['accuracy']==0.5] = 2    \n",
        "    label_df['accuracy_group'][label_df['accuracy']<0.5] = 1\n",
        "    label_df['accuracy_group'][label_df['accuracy']==0] = 0    \n",
        "    return label_df\n",
        "\n",
        "\n",
        "def extract_data_from_event_code(df, columns=['correct', 'round']):\n",
        "    for col in columns:\n",
        "        col_bool = df['event_data'].str.contains(col)\n",
        "        df[col] = np.nan\n",
        "        df[col][col_bool] = df['event_data'][col_bool].apply(lambda x: json.loads(x).get(col)).astype(float)\n",
        "\n",
        "        \n",
        "def get_train_sample_indices(df):\n",
        "    sample_indices = []\n",
        "    inst_indiecs = []    \n",
        "    df_groups = df.groupby('installation_id').groups\n",
        "    for inst_idx, indices in enumerate(df_groups.values()):\n",
        "        one_df = df.iloc[indices].reset_index(drop=True)\n",
        "        assessment_start_indices = one_df[(one_df['type']=='Assessment')&\n",
        "                                          (one_df['accuracy_group']>=0)\n",
        "                                         ].index\n",
        "        for num, start_index in enumerate(assessment_start_indices):\n",
        "            sample_indices.append( one_df.iloc[:start_index+1]['row_id'].tolist() )\n",
        "            inst_indiecs.append(inst_idx)            \n",
        "    return sample_indices, inst_indiecs\n",
        "\n",
        "# 訓練データをランダムサンプリングする？\n",
        "def choose_one(train_samples, train_groups, random_state):    \n",
        "    random.seed(random_state)    \n",
        "    group_dict = {}\n",
        "    for row_id, group in zip(train_samples, train_groups):\n",
        "        if group not in group_dict:\n",
        "            group_dict[group] = []\n",
        "        group_dict[group].append(row_id)\n",
        "    new_train_samples = []    \n",
        "    for v in group_dict.values():        \n",
        "        new_train_samples.append(random.choice(v))         \n",
        "    \n",
        "    return np.array(new_train_samples)\n",
        "\n",
        "def preprocessing(df, train_columns, mappers_dict, cate_offset, cate_cols, cont_cols, extra_cont_cls):\n",
        "    print('preprocessing ... ')\n",
        "    replace_4110_4100(df)\n",
        "    \n",
        "    print('generating label ...')\n",
        "    label_df = gen_label(df)\n",
        "    \n",
        "    print('extract_data_from_event_code ...')\n",
        "    extract_data_from_event_code(df)\n",
        "    df['num_incorrect'] = np.where(df['correct']==0, 1, np.nan)\n",
        "    df['num_correct'] = np.where(df['correct']==1, 1, np.nan)\n",
        "    \n",
        "    df['game_time'] = df['game_time'] // 1000\n",
        "    \n",
        "    df = get_agged_session(df)\n",
        "    df = df.drop(['correct', 'round', 'num_correct', 'num_incorrect'], axis=1)\n",
        "    \n",
        "    df = df.merge(label_df, on=['game_session', 'installation_id'], how='left')\n",
        "    \n",
        "    samples, groups = get_train_sample_indices(df)\n",
        "    \n",
        "    df = df.append(pd.DataFrame(columns=train_columns))[train_columns]\n",
        "    df = df.fillna(0)\n",
        "    \n",
        "    for col in cate_cols:\n",
        "        df[col] = df[col].map(mappers_dict[col]).fillna(0).astype(int)\n",
        "    \n",
        "    print('preprocessing ... done')        \n",
        "    return df, samples, groups\n",
        "\n",
        "# QWKの計算\n",
        "@jit\n",
        "def qwk3(a1, a2, max_rat=3):\n",
        "    assert(len(a1) == len(a2))\n",
        "    a1 = np.asarray(a1, dtype=int)\n",
        "    a2 = np.asarray(a2, dtype=int)\n",
        "\n",
        "    hist1 = np.zeros((max_rat + 1, ))\n",
        "    hist2 = np.zeros((max_rat + 1, ))\n",
        "\n",
        "    o = 0\n",
        "    for k in range(a1.shape[0]):\n",
        "        i, j = a1[k], a2[k]\n",
        "        hist1[i] += 1\n",
        "        hist2[j] += 1\n",
        "        o +=  (i - j) * (i - j)\n",
        "\n",
        "    e = 0\n",
        "    for i in range(max_rat + 1):\n",
        "        for j in range(max_rat + 1):\n",
        "            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n",
        "\n",
        "    e = e / a1.shape[0]\n",
        "\n",
        "    return 1 - o / (e+1e-08)\n",
        "\n",
        "\n",
        "# QWKを最適化するための閾値を見つける\n",
        "class OptimizedRounder(object):\n",
        "    \"\"\"\n",
        "    An optimizer for rounding thresholds\n",
        "    to maximize Quadratic Weighted Kappa (QWK) score\n",
        "    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.coef_ = 0\n",
        "\n",
        "    def _kappa_loss(self, coef, X, y):\n",
        "        \"\"\"\n",
        "        Get loss according to\n",
        "        using current coefficients\n",
        "        \n",
        "        :param coef: A list of coefficients that will be used for rounding\n",
        "        :param X: The raw predictions\n",
        "        :param y: The ground truth labels\n",
        "        \"\"\"\n",
        "        # coefの次元はどれくらいだろうか？初期値が3次元だったので、3次元。\n",
        "        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
        "\n",
        "        # 閾値をもとにQWKを計算。最小化したいので負値になっている。\n",
        "        return -qwk3(y, X_p)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Optimize rounding thresholds\n",
        "        \n",
        "        :param X: The raw predictions\n",
        "        :param y: The ground truth labels\n",
        "        \"\"\"\n",
        "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
        "        initial_coef = [0.5, 1.5, 2.5]\n",
        "        # scipyのoptimize関数で最小化する。\n",
        "        self.coef_ = optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
        "\n",
        "    def predict(self, X, coef):\n",
        "        \"\"\"\n",
        "        Make predictions with specified thresholds\n",
        "        \n",
        "        :param X: The raw predictions\n",
        "        :param coef: A list of coefficients that will be used for rounding\n",
        "        \"\"\"\n",
        "        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
        "\n",
        "    def coefficients(self):\n",
        "        \"\"\"\n",
        "        Return the optimized coefficients\n",
        "        \"\"\"\n",
        "        return self.coef_['x']\n",
        "\n",
        "# quadratic weighted kappaの最適化を行い、kappa scoreを返す\n",
        "def get_optimized_kappa_score(predictions, groundtruth):\n",
        "    # 最適化のクラスを呼び出し\n",
        "    optR = OptimizedRounder()\n",
        "    # 目的関数の最小化により係数を計算する\n",
        "    optR.fit(predictions, groundtruth)\n",
        "    # 最小化した係数\n",
        "    coefficients = optR.coefficients()\n",
        "    #print(coefficients)\n",
        "    temp_predictions = predictions.copy()\n",
        "    temp_predictions[temp_predictions < coefficients[0]] = 0\n",
        "    temp_predictions[(coefficients[0]<=temp_predictions)&(temp_predictions< coefficients[1])] = 1\n",
        "    temp_predictions[(coefficients[1]<=temp_predictions)&(temp_predictions< coefficients[2])] = 2\n",
        "    temp_predictions[(coefficients[2]<=temp_predictions)] = 3\n",
        "\n",
        "    # QWKの計算\n",
        "    kappa_score = qwk3(temp_predictions, groundtruth)\n",
        "    return kappa_score, coefficients \n",
        "\n",
        "# パラメータの設定\n",
        "class CFG:\n",
        "    learning_rate=1.0e-4\n",
        "    batch_size=64\n",
        "    num_workers=4\n",
        "    print_freq=100\n",
        "    test_freq=1\n",
        "    start_epoch=0\n",
        "    num_train_epochs=1\n",
        "    warmup_steps=30\n",
        "    max_grad_norm=1000\n",
        "    gradient_accumulation_steps=1\n",
        "    weight_decay=0.01    \n",
        "    dropout=0.2\n",
        "    emb_size=100 # 分散表現の次元\n",
        "    hidden_size=500 # 隠れ層の数\n",
        "    nlayers=2\n",
        "    nheads=8    \n",
        "    device='cpu'\n",
        "    seed=7\n",
        "    ntta = [0, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6] # TEST KAPPA_SCORE:0.5990772768904306\n",
        "    wtta = [0.8]\n",
        "CFG.wtta += [ (1-CFG.wtta[0])/(len(CFG.ntta)-1) for _ in range(len(CFG.ntta)-1)]\n",
        "\n",
        "# .pyファイルを実行して行う処理\n",
        "def main():\n",
        "    # 乱数の固定\n",
        "    os.environ['PYTHONHASHSEED'] = str(CFG.seed)\n",
        "    random.seed(CFG.seed)\n",
        "    np.random.seed(CFG.seed)\n",
        "    torch.manual_seed(CFG.seed)    \n",
        "    torch.cuda.manual_seed(CFG.seed)\n",
        "    torch.backends.cudnn.deterministic = True       \n",
        "    \n",
        "    test_df = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\n",
        "\n",
        "    [train_columns, mappers_dict, cate_offset, \n",
        "     cate_cols, cont_cols, extra_cont_cls] = torch.load('/kaggle/input/dsb2019-models/bowl_info_v70.pt')\n",
        "    test_df, test_samples, test_groups = preprocessing(test_df, train_columns, mappers_dict, cate_offset, \n",
        "                            cate_cols, cont_cols, extra_cont_cls)    \n",
        "    \n",
        "    CFG.target_size = 3\n",
        "    CFG.total_cate_size = cate_offset\n",
        "    print(CFG.__dict__)\n",
        "    CFG.cate_cols = cate_cols\n",
        "    CFG.cont_cols = cont_cols+extra_cont_cls    \n",
        "        \n",
        "    base_model_path_list = [\n",
        "        ['bowl_v62.pt', [\n",
        "            [1.0, f'/kaggle/input/dsb2019-models/v64/b-32_a-TRANSFORMER_e-100_h-500_d-0.2_l-2_hd-10_s-7_len-100_aug-0.5_da-bowl_v62.pt_k-0.pt'],            \n",
        "        ]],\n",
        "    ]\n",
        "\n",
        "    ################################################\n",
        "    # find the coefficients\n",
        "    ################################################\n",
        "    rand_seed_list = [7, 77, 777, 1, 2]\n",
        "    #rand_seed_list = [110798, 497274, 885651, 673327, 599183, 272713, 582394, 180043, 855725, 932850]    \n",
        "    sum_coefficients = 0\n",
        "    sum_cnt = 0\n",
        "    for _, base_model_paths in base_model_path_list:        \n",
        "        for model_w, base_model_path in base_model_paths:        \n",
        "            path = base_model_path.split('/')[-1]\n",
        "            path = path.replace('bowl_', '')\n",
        "            cfg_dict = dict([tok.split('-') for tok in path.split('_')])\n",
        "            CFG.encoder = cfg_dict['a']\n",
        "            CFG.seq_len = int(cfg_dict['len'])\n",
        "            CFG.emb_size = int(cfg_dict['e'])\n",
        "            CFG.hidden_size = int(cfg_dict['h'])\n",
        "            CFG.nlayers = int(cfg_dict['l'])\n",
        "            CFG.nheads = int(cfg_dict['hd'])\n",
        "            CFG.seed = int(cfg_dict['s'])\n",
        "            CFG.data_seed = int(cfg_dict['s'])\n",
        "            \n",
        "            for k in range(5):\n",
        "                # エンコーダを指定して、CFGのパラメータを設定？\n",
        "                model = ENCODERS[CFG.encoder](CFG)\n",
        "                model_path = base_model_path.replace('k-0', f'k-{k}')\n",
        "                \n",
        "                checkpoint = torch.load(model_path, map_location=CFG.device)        \n",
        "                model.load_state_dict(checkpoint['state_dict'])\n",
        "                model.to(CFG.device)\n",
        "                print(\"=> loaded checkpoint '{}' (epoch {})\".format(model_path, checkpoint['epoch']))            \n",
        "                \n",
        "                for rand_seed in rand_seed_list:\n",
        "                    chosen_samples = choose_one(test_samples, test_groups, random_state=rand_seed)\n",
        "                    predictions = 0    \n",
        "                    for w, tta in zip(CFG.wtta, CFG.ntta):\n",
        "                        padding_front = False if CFG.encoder=='LSTM' else True\n",
        "                        valid_db = BowlDataset(CFG, test_df, chosen_samples, aug=tta, aug_p=1.0, \n",
        "                                               padding_front=padding_front, use_tta=True)\n",
        "                        valid_loader = DataLoader(\n",
        "                                valid_db, batch_size=CFG.batch_size, shuffle=False,\n",
        "                                num_workers=CFG.num_workers, pin_memory=True)\n",
        "                        # クロスバリデーションで予測値と実績値を返す            \n",
        "                        prediction, groundtruths = validate(valid_loader, model)\n",
        "                        predictions += w*prediction                                            \n",
        "                    try:\n",
        "                        valid_kappa, valid_coefficients = get_optimized_kappa_score(predictions, groundtruths)\n",
        "                        print(f'k[{k}]-s2[{rand_seed}]: valid_kappa:{valid_kappa} - {valid_coefficients}') \n",
        "                        sum_coefficients += np.array(valid_coefficients)\n",
        "                        sum_cnt += 1\n",
        "                    except Exception as e:\n",
        "                        print(e)\n",
        "                        print(f'k[{k}]-s2[{rand_seed}]: valid_kappa: Failed!')\n",
        "                        pass\n",
        "                del model\n",
        "    ################################################\n",
        "    test_samples = list(test_df.groupby(['installation_id']).groups.values())    \n",
        "    \n",
        "    coefficients = 0.5*sum_coefficients/sum_cnt + 0.5*np.array([0.53060865, 1.66266655, 2.31145611])       \n",
        "    print('=======================================')\n",
        "    print(f'coefficients - {coefficients}')\n",
        "    print('=======================================')\n",
        "    \n",
        "    random.seed(CFG.seed)\n",
        "    \n",
        "    submission_df = test_df.groupby('installation_id').tail(1)[['installation_id']]\n",
        "    submission_df['accuracy_group'] = 0\n",
        "    \n",
        "    for _, base_model_paths in base_model_path_list:\n",
        "        for model_w, base_model_path in base_model_paths:        \n",
        "            path = base_model_path.split('/')[-1]\n",
        "            path = path.replace('bowl_', '')\n",
        "            cfg_dict = dict([tok.split('-') for tok in path.split('_')])\n",
        "            CFG.encoder = cfg_dict['a']\n",
        "            CFG.seq_len = int(cfg_dict['len'])\n",
        "            CFG.emb_size = int(cfg_dict['e'])\n",
        "            CFG.hidden_size = int(cfg_dict['h'])\n",
        "            CFG.nlayers = int(cfg_dict['l'])\n",
        "            CFG.nheads = int(cfg_dict['hd'])\n",
        "            CFG.seed = int(cfg_dict['s'])\n",
        "            CFG.data_seed = int(cfg_dict['s'])\n",
        "            \n",
        "            for k in range(5):\n",
        "                # あるモデルに関して、CFGで定義したパラメータ\n",
        "                model = ENCODERS[CFG.encoder](CFG)\n",
        "                model_path = base_model_path.replace('k-0', f'k-{k}')\n",
        "                \n",
        "                checkpoint = torch.load(model_path, map_location=CFG.device)        \n",
        "                model.load_state_dict(checkpoint['state_dict'])\n",
        "                model.to(CFG.device)\n",
        "                print(\"=> loaded checkpoint '{}' (epoch {})\".format(model_path, checkpoint['epoch']))            \n",
        "                                      \n",
        "                for w, tta in zip(CFG.wtta, CFG.ntta):\n",
        "                    padding_front = False if CFG.encoder=='LSTM' else True\n",
        "                    valid_db = BowlDataset(CFG, test_df, test_samples, aug=tta, aug_p=1.0, \n",
        "                                           padding_front=padding_front, use_tta=True)\n",
        "                    valid_loader = DataLoader(\n",
        "                            valid_db, batch_size=CFG.batch_size, shuffle=False,\n",
        "                            num_workers=CFG.num_workers, pin_memory=True)\n",
        "                    # このtestは下部で定義している。           \n",
        "                    predictions = test(valid_loader, model)\n",
        "                    submission_df['accuracy_group'] += w*predictions*model_w*(1/5)\n",
        "                del model\n",
        "    \n",
        "    submission_df['accuracy_group'] /= len(base_model_path_list)\n",
        "    compute_th_acc_gp(submission_df['accuracy_group'], coefficients) \n",
        "    submission_df['accuracy_group'] = submission_df['accuracy_group'].astype(int)\n",
        "    submission_df.to_csv('submission.csv', index=False)\n",
        "    print('done')\n",
        "\n",
        "def compute_th_acc_gp(temp, coef):\n",
        "    temp[temp < coef[0]] = 0\n",
        "    temp[(coef[0]<=temp)&(temp< coef[1])] = 1\n",
        "    temp[(coef[1]<=temp)&(temp< coef[2])] = 2\n",
        "    temp[(coef[2]<=temp)] = 3    \n",
        "\n",
        "# 予測結果の1番目を3倍したもの、予測結果の2番目を2倍したものの差分、負であれば0を返す。\n",
        "# グループを予測しているということ？\n",
        "def compute_acc_gp(pred):\n",
        "    #batch_size = pred.size(0)\n",
        "    pred = (3*pred[:, 0] - 2*pred[:, 1])    \n",
        "    pred[pred < 0] = 0    \n",
        "    return pred\n",
        "\n",
        "# バリデーションのための予測\n",
        "def validate(valid_loader, model):\n",
        "    # lstmなどのモデルを読み込む\n",
        "    # modelは結局のところクラスになっている。それを実行するための記述らしい。\n",
        "    model.eval()    \n",
        "    \n",
        "    predictions = []\n",
        "    # ground truth data : 正確さや整合性をチェックするためのデータ\n",
        "    groundtruths = []\n",
        "\n",
        "    # testのタプルには3つだが、教師データがあるので4つのタプルになる。\n",
        "    for step, (cate_x, cont_x, mask, y) in enumerate(valid_loader):\n",
        "        \n",
        "        # CFGのクラスにあるdeviceで、cpuに指定している。\n",
        "        cate_x, cont_x, mask = cate_x.to(CFG.device), cont_x.to(CFG.device), mask.to(CFG.device)        \n",
        "        \n",
        "        k = 0.5\n",
        "        # 勾配の計算を初期化している。\n",
        "        with torch.no_grad():\n",
        "            # modelに値を入れると予測結果が吐かれるぽい。\n",
        "            pred = model(cate_x, cont_x, mask)\n",
        "          \n",
        "        # record accuracy\n",
        "        pred_y = (1-k)*pred[:, 0] + (k)*compute_acc_gp(pred[:, 1:])\n",
        "        predictions.append(pred_y.detach().cpu())\n",
        "        # 実績値の更新\n",
        "        groundtruths.append(y[:, 0])\n",
        "\n",
        "    predictions = torch.cat(predictions).numpy()\n",
        "    groundtruths = torch.cat(groundtruths).numpy()\n",
        "    \n",
        "    return predictions, groundtruths\n",
        "\n",
        "\n",
        "# テストデータに関する予測\n",
        "def test(valid_loader, model):\n",
        "    # lstmなどのモデルを読み込む\n",
        "    # modelは結局のところクラスになっている。それを実行するための記述らしい。\n",
        "    model.eval()    \n",
        "    \n",
        "    predictions = []\n",
        "    # このmaskはBERTの論文にあった、あのマスク？\n",
        "    # valid_loaderって何？torchのDataLoader()のこと。\n",
        "    # enumerateはカウントとタプルを返す\n",
        "    for step, (cate_x, cont_x, mask, _) in enumerate(valid_loader):\n",
        "        \n",
        "        # CFGのクラスにあるdeviceで、cpuに指定している。\n",
        "        cate_x, cont_x, mask = cate_x.to(CFG.device), cont_x.to(CFG.device), mask.to(CFG.device)        \n",
        "        \n",
        "        k = 0.5\n",
        "        # 勾配の計算を初期化している。\n",
        "        with torch.no_grad():\n",
        "            # modelに値を入れると予測結果が吐かれるぽい。classの定義でそうなっていた。\n",
        "            pred = model(cate_x, cont_x, mask)\n",
        "          \n",
        "        # record accuracy\n",
        "        # kで重み付けをしている。ここでは0.5にしている。\n",
        "        # compute_acc_gpは？\n",
        "        pred_y = (1-k)*pred[:, 0] + (k)*compute_acc_gp(pred[:, 1:])\n",
        "        # variable型からtensor型を取り出す際ためにdetachを用いている。\n",
        "        predictions.append(pred_y.detach().cpu())        \n",
        "\n",
        "    # torch.cat()でtensorを連結する\n",
        "    predictions = torch.cat(predictions).numpy()\n",
        "    \n",
        "    return predictions\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQlKXhPPxSnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}